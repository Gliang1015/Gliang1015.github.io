<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>爬虫-02</title>
      <link href="/2024/07/06/crawler02/"/>
      <url>/2024/07/06/crawler02/</url>
      
        <content type="html"><![CDATA[<h1 id="爬虫-02"><a href="#爬虫-02" class="headerlink" title="爬虫-02"></a>爬虫-02</h1><h2 id="POST请求"><a href="#POST请求" class="headerlink" title="POST请求"></a>POST请求</h2><p>这里是以<a href="http://www.17k.com进行的练习./">www.17k.com进行的练习。</a></p><h3 id="get请求与post请求"><a href="#get请求与post请求" class="headerlink" title="get请求与post请求"></a>get请求与post请求</h3><ul><li>get：直接向服务端请求资源响应。</li><li>post：首先携带数据给服务器，然后再得到提交数据之后的资源响应。</li></ul><h3 id="cookies的用途"><a href="#cookies的用途" class="headerlink" title="cookies的用途"></a>cookies的用途</h3><p>使用cookie拿到登录过后的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url_ = <span class="string">&#x27;https://user.17k.com/ck/author2/shelf?page=1&amp;appKey=2406394919&#x27;</span></span><br><span class="line">    headers_ = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    response_ = requests.get(url_, headers=headers_)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(response_.text)</span><br></pre></td></tr></table></figure><p>当我们运行爬虫程序时，结果显示：<br><img src="/img/crawler02/01.png"><br>但在浏览器访问该网站时，服务器返还的是：<br><img src="/img/crawler02/02.png"><br>这是因为我们的浏览器中有我们登录账号的缓存信息，当我们访问该网站时，会自动携带上cookie。<br>所以我们可以通过伪造cookie的方式获取到我们想要获取的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url_ = <span class="string">&#x27;https://user.17k.com/ck/author2/shelf?page=1&amp;appKey=2406394919&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加cookie的方法</span></span><br><span class="line">    <span class="comment"># 第一种方法：直接在headers中添加cookie</span></span><br><span class="line">    headers_ = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0&#x27;</span>,</span><br><span class="line">        <span class="comment"># &#x27;Cookie&#x27;: &#x27;GUID=3d5c0a1c-6443-4cbd-b00b-22b85bb01f05; acw_sc__v2=668756f65ffdf1cba6ea96efed3e7a76b344a562; Hm_lvt_9793f42b498361373512340937deb2a0=1720145654; HMACCOUNT=C61541FFCB75FC53; sajssdk_2015_cross_new_user=1; c_channel=0; c_csc=web; accessToken=avatarUrl%3Dhttps%253A%252F%252Fcdn.static.17k.com%252Fuser%252Favatar%252F17%252F77%252F20%252F103222077.jpg-88x88%253Fv%253D1709796823000%26id%3D103222077%26nickname%3Dliang03959429%26e%3D1735697841%26s%3D03dc284cfa344db4; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%22103222077%22%2C%22%24device_id%22%3A%2219080abb293f73-089e4d04ccd23-4c657b58-2073600-19080abb294e55%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_referrer%22%3A%22%22%2C%22%24latest_referrer_host%22%3A%22%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%7D%2C%22first_id%22%3A%223d5c0a1c-6443-4cbd-b00b-22b85bb01f05%22%7D; ssxmod_itna=QqmxBD2DnDcCDQGkDzEiTWmlFQw=3j+x0KQD/i7IDnqD=GFDK40Eo7PwvE=4I5qrtZkDKDgjoP05EQQG2owr7b1+2oDU4i8DCLDK4TDee=D5xGoDPxDeDAYKiTDY4DdLwds=DEDeKDRDAQDzwL9DG3BDYpc3qDgBqDBCrdDKqGgCMxD0MhtgGmxQ7rgnfrDEeDSKitei7=DjubD/+xOs7=Yv695jTUak=2T3TixxBQD7q0cDYoUAeDHCqXegrhTYiho9gGoG4hxi0DwWBhxYokKbsx4Yo+jVKYeY0Y0yg4McKDAiGwoQxxxD; ssxmod_itna2=QqmxBD2DnDcCDQGkDzEiTWmlFQw=3j+x0KG9QwWDRxGXxKPGaWY7m5i7+krmx8hmQeNSoM20+u/rYOLkQ13Q32FKDt0o4sVRF1xF6TZFQTB66j1UASURC=DEMfe+DCFcxOvHj0Sn92yd=o7Cvhi8M=wdc1vTeQpiArG+XpKWbRKhyi5W9r5HCR9bsRICpIKheEc3Dc31RhiTs=cF86xiegqrP1cNL+FLV+nHdh0LUQcaaEliYSETmSnz+IIwU0POFN5+RE19tg1BgSnX5hqNIweo6A/ienUNYPrMuF/QuFnNsFU1gy/a/yN8pDxFgFFgzaVtHa9yiU5qcy=YI/0wu8HFi+dCHqk4P=4bY02DotjKbQidKwWDRV4nVeI9e9VladOg3=HaGRUSqgATekrjCI4YoZ4S37vlmx3T3q3biNKqYEN2okSOaEfr0ffK5FTSHYHCmSqQxDKweSDzDwxYYGm7KvcxZ7HL66BgxqA5hm6nAreixq0Ddc5+l3c0toYXtd46R6RGDLi5Ra2Q9UYDDLxD2zGDD===; tfstk=fTR2rwVgtjhqttvG4g1NYcThTj5AT6nQ_Cs1SFYGlij0GSZMUN_dGOmAGC-PMQ9b1iiA_FxC_DiIOXTvk_CiADOxoIbNtN70m-q_Ea4CSVXEOXTvoufg8jlIWlU5NGIGstXGZajR7R4DjtbuqgQOSobgi48l2NfgiGXcZubC5G4cIXWJoFVPRt03ofpioD4REMYcmETXZrXbHEIzs5AyUtSnigPgsQ72ycI7HWk1xpIfdgKoNS5wrN-F8nro41YyMBWki0FwY3Jhaap-bRSeIE9pITumiU5V09R5Fr2Ngdxv_tp4W2Lli3pdvtD-2aRXOOSdUumDPUScLd-j25jXLUxPdQZ7O_YHU_SrglQlFjO93l2NnaQPA4uoV-KGbCkADkyTBTfdzMgflReOnaQPA4uzBRBl9aSIlZ1..; Hm_lpvt_9793f42b498361373512340937deb2a0=1720145953&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 第二种方法：单独构建一个字典来携带cookie</span></span><br><span class="line">    <span class="comment"># cookies_ = &#123;</span></span><br><span class="line">    <span class="comment">#     &#x27;Cookie&#x27;: &#x27;GUID=3d5c0a1c-6443-4cbd-b00b-22b85bb01f05; acw_sc__v2=668756f65ffdf1cba6ea96efed3e7a76b344a562; Hm_lvt_9793f42b498361373512340937deb2a0=1720145654; HMACCOUNT=C61541FFCB75FC53; sajssdk_2015_cross_new_user=1; c_channel=0; c_csc=web; accessToken=avatarUrl%3Dhttps%253A%252F%252Fcdn.static.17k.com%252Fuser%252Favatar%252F17%252F77%252F20%252F103222077.jpg-88x88%253Fv%253D1709796823000%26id%3D103222077%26nickname%3Dliang03959429%26e%3D1735697841%26s%3D03dc284cfa344db4; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%22103222077%22%2C%22%24device_id%22%3A%2219080abb293f73-089e4d04ccd23-4c657b58-2073600-19080abb294e55%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_referrer%22%3A%22%22%2C%22%24latest_referrer_host%22%3A%22%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%7D%2C%22first_id%22%3A%223d5c0a1c-6443-4cbd-b00b-22b85bb01f05%22%7D; ssxmod_itna=QqmxBD2DnDcCDQGkDzEiTWmlFQw=3j+x0KQD/i7IDnqD=GFDK40Eo7PwvE=4I5qrtZkDKDgjoP05EQQG2owr7b1+2oDU4i8DCLDK4TDee=D5xGoDPxDeDAYKiTDY4DdLwds=DEDeKDRDAQDzwL9DG3BDYpc3qDgBqDBCrdDKqGgCMxD0MhtgGmxQ7rgnfrDEeDSKitei7=DjubD/+xOs7=Yv695jTUak=2T3TixxBQD7q0cDYoUAeDHCqXegrhTYiho9gGoG4hxi0DwWBhxYokKbsx4Yo+jVKYeY0Y0yg4McKDAiGwoQxxxD; ssxmod_itna2=QqmxBD2DnDcCDQGkDzEiTWmlFQw=3j+x0KG9QwWDRxGXxKPGaWY7m5i7+krmx8hmQeNSoM20+u/rYOLkQ13Q32FKDt0o4sVRF1xF6TZFQTB66j1UASURC=DEMfe+DCFcxOvHj0Sn92yd=o7Cvhi8M=wdc1vTeQpiArG+XpKWbRKhyi5W9r5HCR9bsRICpIKheEc3Dc31RhiTs=cF86xiegqrP1cNL+FLV+nHdh0LUQcaaEliYSETmSnz+IIwU0POFN5+RE19tg1BgSnX5hqNIweo6A/ienUNYPrMuF/QuFnNsFU1gy/a/yN8pDxFgFFgzaVtHa9yiU5qcy=YI/0wu8HFi+dCHqk4P=4bY02DotjKbQidKwWDRV4nVeI9e9VladOg3=HaGRUSqgATekrjCI4YoZ4S37vlmx3T3q3biNKqYEN2okSOaEfr0ffK5FTSHYHCmSqQxDKweSDzDwxYYGm7KvcxZ7HL66BgxqA5hm6nAreixq0Ddc5+l3c0toYXtd46R6RGDLi5Ra2Q9UYDDLxD2zGDD===; tfstk=fTR2rwVgtjhqttvG4g1NYcThTj5AT6nQ_Cs1SFYGlij0GSZMUN_dGOmAGC-PMQ9b1iiA_FxC_DiIOXTvk_CiADOxoIbNtN70m-q_Ea4CSVXEOXTvoufg8jlIWlU5NGIGstXGZajR7R4DjtbuqgQOSobgi48l2NfgiGXcZubC5G4cIXWJoFVPRt03ofpioD4REMYcmETXZrXbHEIzs5AyUtSnigPgsQ72ycI7HWk1xpIfdgKoNS5wrN-F8nro41YyMBWki0FwY3Jhaap-bRSeIE9pITumiU5V09R5Fr2Ngdxv_tp4W2Lli3pdvtD-2aRXOOSdUumDPUScLd-j25jXLUxPdQZ7O_YHU_SrglQlFjO93l2NnaQPA4uoV-KGbCkADkyTBTfdzMgflReOnaQPA4uzBRBl9aSIlZ1..; Hm_lpvt_9793f42b498361373512340937deb2a0=1720145953&#x27;</span></span><br><span class="line">    <span class="comment"># &#125;</span></span><br><span class="line">    <span class="comment"># 第三种方法：应对cookie值失效的情况</span></span><br><span class="line">    cookies_ = <span class="string">&#x27;GUID=3d5c0a1c-6443-4cbd-b00b-22b85bb01f05; acw_sc__v2=668756f65ffdf1cba6ea96efed3e7a76b344a562; Hm_lvt_9793f42b498361373512340937deb2a0=1720145654; HMACCOUNT=C61541FFCB75FC53; sajssdk_2015_cross_new_user=1; c_channel=0; c_csc=web; accessToken=avatarUrl%3Dhttps%253A%252F%252Fcdn.static.17k.com%252Fuser%252Favatar%252F17%252F77%252F20%252F103222077.jpg-88x88%253Fv%253D1709796823000%26id%3D103222077%26nickname%3Dliang03959429%26e%3D1735697841%26s%3D03dc284cfa344db4; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%22103222077%22%2C%22%24device_id%22%3A%2219080abb293f73-089e4d04ccd23-4c657b58-2073600-19080abb294e55%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_referrer%22%3A%22%22%2C%22%24latest_referrer_host%22%3A%22%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%7D%2C%22first_id%22%3A%223d5c0a1c-6443-4cbd-b00b-22b85bb01f05%22%7D; ssxmod_itna=QqmxBD2DnDcCDQGkDzEiTWmlFQw=3j+x0KQD/i7IDnqD=GFDK40Eo7PwvE=4I5qrtZkDKDgjoP05EQQG2owr7b1+2oDU4i8DCLDK4TDee=D5xGoDPxDeDAYKiTDY4DdLwds=DEDeKDRDAQDzwL9DG3BDYpc3qDgBqDBCrdDKqGgCMxD0MhtgGmxQ7rgnfrDEeDSKitei7=DjubD/+xOs7=Yv695jTUak=2T3TixxBQD7q0cDYoUAeDHCqXegrhTYiho9gGoG4hxi0DwWBhxYokKbsx4Yo+jVKYeY0Y0yg4McKDAiGwoQxxxD; ssxmod_itna2=QqmxBD2DnDcCDQGkDzEiTWmlFQw=3j+x0KG9QwWDRxGXxKPGaWY7m5i7+krmx8hmQeNSoM20+u/rYOLkQ13Q32FKDt0o4sVRF1xF6TZFQTB66j1UASURC=DEMfe+DCFcxOvHj0Sn92yd=o7Cvhi8M=wdc1vTeQpiArG+XpKWbRKhyi5W9r5HCR9bsRICpIKheEc3Dc31RhiTs=cF86xiegqrP1cNL+FLV+nHdh0LUQcaaEliYSETmSnz+IIwU0POFN5+RE19tg1BgSnX5hqNIweo6A/ienUNYPrMuF/QuFnNsFU1gy/a/yN8pDxFgFFgzaVtHa9yiU5qcy=YI/0wu8HFi+dCHqk4P=4bY02DotjKbQidKwWDRV4nVeI9e9VladOg3=HaGRUSqgATekrjCI4YoZ4S37vlmx3T3q3biNKqYEN2okSOaEfr0ffK5FTSHYHCmSqQxDKweSDzDwxYYGm7KvcxZ7HL66BgxqA5hm6nAreixq0Ddc5+l3c0toYXtd46R6RGDLi5Ra2Q9UYDDLxD2zGDD===; tfstk=fTR2rwVgtjhqttvG4g1NYcThTj5AT6nQ_Cs1SFYGlij0GSZMUN_dGOmAGC-PMQ9b1iiA_FxC_DiIOXTvk_CiADOxoIbNtN70m-q_Ea4CSVXEOXTvoufg8jlIWlU5NGIGstXGZajR7R4DjtbuqgQOSobgi48l2NfgiGXcZubC5G4cIXWJoFVPRt03ofpioD4REMYcmETXZrXbHEIzs5AyUtSnigPgsQ72ycI7HWk1xpIfdgKoNS5wrN-F8nro41YyMBWki0FwY3Jhaap-bRSeIE9pITumiU5V09R5Fr2Ngdxv_tp4W2Lli3pdvtD-2aRXOOSdUumDPUScLd-j25jXLUxPdQZ7O_YHU_SrglQlFjO93l2NnaQPA4uoV-KGbCkADkyTBTfdzMgflReOnaQPA4uzBRBl9aSIlZ1..; Hm_lpvt_9793f42b498361373512340937deb2a0=1720145953&#x27;</span></span><br><span class="line">    cookies_ = &#123;</span><br><span class="line">        i.split(<span class="string">&#x27;=&#x27;</span>,<span class="number">1</span>)[<span class="number">0</span>] : i.split(<span class="string">&#x27;=&#x27;</span>,<span class="number">1</span>)[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> cookies_.split(<span class="string">&#x27;;&#x27;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># print(cookies_)</span></span><br><span class="line"></span><br><span class="line">    response_ = requests.get(url_, headers=headers_, cookies=cookies_)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(response_.text)</span><br></pre></td></tr></table></figure><p>这样，我们就可以通过爬虫程序获取我们想要的信息了。<br><img src="/img/crawler02/03.png"></p><h3 id="post请求模拟登录"><a href="#post请求模拟登录" class="headerlink" title="post请求模拟登录"></a>post请求模拟登录</h3><p>在模拟登录前，我们应该找到登录的url，这里我使用的是抓包的方式，先输错一次账号或者密码，会发现收一个login的包：<br><img src="/img/crawler02/04.png"><br>里面有我们所需的信息，方便我们接下来的模拟登录。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url_ = <span class="string">&#x27;https://passport.17k.com/ck/user/login&#x27;</span></span><br><span class="line"></span><br><span class="line">    headers_ = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模拟登录，就不需要携带登录信息了</span></span><br><span class="line">    <span class="comment"># post请求需要携带数据，form表单里携带数据</span></span><br><span class="line"></span><br><span class="line">    form_data = &#123;</span><br><span class="line">        <span class="string">&#x27;loginName&#x27;</span>: <span class="string">&#x27;17839160637&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;G.L1015&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    respose_ = requests.post(url_, headers=headers_, data=form_data)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(respose_.text)</span><br></pre></td></tr></table></figure><p>相较于通过cookie拿到登录过后的信息，使用模拟登录，更为方便，而且cookie还面临着过期的问题。</p><h3 id="session自动携带cookie"><a href="#session自动携带cookie" class="headerlink" title="session自动携带cookie"></a>session自动携带cookie</h3><p>在面对多个页面的爬取时，使用post请求模拟登录会出现每个页面的爬取都需要登录一次情况，容易被检查到非正常用户，从而被封禁账号。<br>因此我们通过使用post请求模拟登录的方法，直接获取登录过后的cookie，在使用这个cookie去发送get请求不同的页面</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    login_url = <span class="string">&#x27;https://passport.17k.com/ck/user/login&#x27;</span></span><br><span class="line"></span><br><span class="line">    headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">    form_data = &#123;</span><br><span class="line">        <span class="string">&quot;loginName&quot;</span>: <span class="string">&#x27;17839160637&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;password&quot;</span>: <span class="string">&#x27;GLzm1015&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 封装一个发送新的请求的对象</span></span><br><span class="line">    session_ = requests.session()</span><br><span class="line"></span><br><span class="line">   <span class="comment"># 使用session发送post请求，进行登录,这样session_对象就有了登录过后的cookie值</span></span><br><span class="line">    session_.post(login_url, data=form_data, headers=headers)</span><br><span class="line"></span><br><span class="line">    read_url = <span class="string">&#x27;https://user.17k.com/ck/author2/shelf?page=1&amp;appKey=2406394919&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用session发送get请求</span></span><br><span class="line">    response_ = session_.get(url=read_url, headers=headers)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(response_.text)</span><br></pre></td></tr></table></figure><h3 id="cookie池"><a href="#cookie池" class="headerlink" title="cookie池"></a>cookie池</h3><p>cookie记录了你的账号与这个服务器的交流，没有cookie可能会导致网站禁止访问，一种反爬的手段，因为cookie是一个网站中与每个账号短时间内一一对应的，所以我们要创建一个cookie池没有特殊的手段。</p><h2 id="闭包以及装饰器"><a href="#闭包以及装饰器" class="headerlink" title="闭包以及装饰器"></a>闭包以及装饰器</h2><h3 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h3><p>如果一个函数在内部不调用其它函数，而是调用它本身的话，这个函数就是递归函数。<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> n &lt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;输入有误&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> n * fun(n-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    num = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入一个数字：&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(fun(num))</span><br><span class="line">    </span><br><span class="line">    f = fun</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">id</span>(f))</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">id</span>(fun))</span><br><span class="line">    <span class="built_in">print</span>(f(<span class="number">5</span>))</span><br><span class="line">    <span class="comment"># 可以发现在f = fun后，f和fun指向的是同一个函数，所以f(5)和fun(5)的结果是一样的，是因为函数名中带有函数的地址，所以f = fun后，f和fun指向的是同一个函数</span></span><br></pre></td></tr></table></figure></p><h3 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h3><p>两个函数的嵌套，内部函数使用到为外部函数的变量，这个现象就可以称之为产生闭包。</p><ul><li>函数嵌套</li><li>内部函数使用到为外部函数</li><li>外部函数返回内部函数的引用<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">out</span>(<span class="params">m</span>):</span><br><span class="line">    n = <span class="number">10</span></span><br><span class="line">    <span class="built_in">print</span>(n)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">        <span class="comment"># 实现修改闭包内使用的外部变量</span></span><br><span class="line">        <span class="keyword">nonlocal</span> n <span class="comment"># 告诉解释器，此处使用的是外部变量n</span></span><br><span class="line">        n = <span class="number">8</span></span><br><span class="line">        <span class="built_in">print</span>(n)</span><br><span class="line">        <span class="built_in">print</span>(n+m)</span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    f = out(<span class="number">5</span>)</span><br><span class="line">    f()</span><br><span class="line">    </span><br><span class="line">终端显示的结果是：</span><br><span class="line"><span class="number">10</span> <span class="number">8</span> <span class="number">13</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>装饰器本质上是一个Python函数，它可以让其它函数在不需要任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fwrapper</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请先登录。。。&#x27;</span>)</span><br><span class="line">        func()</span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line"><span class="comment"># 语法塘调用</span></span><br><span class="line"><span class="comment"># 当多个修饰器修饰一个函数时，离的近的先修饰</span></span><br><span class="line"><span class="meta">@fwrapper</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ffunc</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;欢迎访问&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类装饰器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">cwrapper</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, func</span>):</span><br><span class="line">        self.func = func</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;哈哈&#x27;</span>)</span><br><span class="line">        self.func()</span><br><span class="line"></span><br><span class="line"><span class="meta">@cwrapper </span><span class="comment"># 等同于 cfunc = cwrapper(cfunc)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cfunc</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;嘻嘻&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># # 一般调用</span></span><br><span class="line">    <span class="comment"># f = fwrapper(func)</span></span><br><span class="line">    <span class="comment"># f() # inner()</span></span><br><span class="line"></span><br><span class="line">    ffunc() <span class="comment"># inner()</span></span><br><span class="line">    cfunc() <span class="comment"># cfunc.__call__()</span></span><br><span class="line"></span><br><span class="line">终端的输出结果是：</span><br><span class="line">请先登录。。。</span><br><span class="line">欢迎访问</span><br><span class="line">哈哈</span><br><span class="line">嘻嘻</span><br><span class="line">哈哈</span><br><span class="line">嘻嘻</span><br></pre></td></tr></table></figure><h2 id="代理IP"><a href="#代理IP" class="headerlink" title="代理IP"></a>代理IP</h2><h3 id="SSL安全认证"><a href="#SSL安全认证" class="headerlink" title="SSL安全认证"></a>SSL安全认证</h3><p>在我们对某些网站进行访问时，有时会提示我们“您的连接不是私密连接”，这是因为ssl的证书不安全，我们正常的用户通过安装一个证书进行解决。<br>对于爬虫程序，会有SSLError的报错，需要我们在发送请求的时候添加一个参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.get(url,verify=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>在我们对网站进行访问时，会询问我们是否进行验证，verify&#x3D;False是在说不需要验证。</p><p>那什么是ssl呢？<br>其实我们在之前已经接触过了，https协议是http与ssl协议的结合，是https相较于http协议多的一重加密。</p><h3 id="代理IP池"><a href="#代理IP池" class="headerlink" title="代理IP池"></a>代理IP池</h3><p>ip是一种定位，我们的设备时常通过路由器连接网络，一般路由器的ip是一级ip，而连接该路由器的每台设备都会由路由器再分配一个二级ip，我们发送数据是先由我们的设备发送给路由器，再又路由器发送给目的地址，而响应返回的数据也是先到达路由器，再又路由器返还给我们个人的设备。<br><img src="/img/crawler02/05.png"><br>代理ip是将自己的ip代理到第三方服务器，在访问目的地址前先访问第三方服务器，以其他的ip去访问目的地址。<br>代理ip池是因为我们有时需要短时间内多次访问同一个服务器，容易被封禁，同用户代理池和cookie池目的一样，都是为了更好的骗过服务器。<br><img src="/img/crawler02/06.png"></p><ul><li>正向代理：对于浏览器知道服务器的真实地址，例如VPN。</li><li>反向代理：浏览器不知道服务器的真实地址，例如nginx。</li></ul><h3 id="代理IP的分类"><a href="#代理IP的分类" class="headerlink" title="代理IP的分类"></a>代理IP的分类</h3><ul><li>透明代理：隐匿行很差，服务器可以简单地检测到你使用的代理ip，并且知道你的真是ip。</li><li>匿名代理：服务器也是可以简单检测到你使用的代理ip，但是不知道你的真实ip。</li><li>高匿代理：服务器检测不到代理ip和真实ip。</li></ul><h3 id="代理IP的使用"><a href="#代理IP的使用" class="headerlink" title="代理IP的使用"></a>代理IP的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    url_ = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line">    headers_ = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建代理ip字典</span></span><br><span class="line">    <span class="comment"># proxies字典中的键名（协议头http/https）--&gt;需要跟请求url的协议头类型保持一致</span></span><br><span class="line">    <span class="comment"># proxies字典中的键值（代理ip）--&gt;代理ip的格式：协议头://ip:端口号</span></span><br><span class="line">    proxies_ = &#123;</span><br><span class="line">        <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://11.11.11.11:8080&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在requests库升级之后，会出现即使ip不能使用也会获取成功的现象，这是因为它发现ip不能使用后，会使用真实的ip进行访问</span></span><br><span class="line">    <span class="comment"># 而有个特殊的网站可以查看当前的ip地址是什么：https://myip.ipip.net/</span></span><br><span class="line">    <span class="comment"># 我们可以根据这个网站然后查看请求代理的ip时候可以使用</span></span><br><span class="line">    test_url = <span class="string">&#x27;https://myip.ipip.net/&#x27;</span></span><br><span class="line"></span><br><span class="line">    test_response = requests.get(url=test_url, headers=headers_, proxies=proxies_)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(test_response.text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># response_ = requests.get(url=url, headers=headers_, proxies=proxies_)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># print(response_.text)</span></span><br></pre></td></tr></table></figure><h3 id="timeout参数的使用"><a href="#timeout参数的使用" class="headerlink" title="timeout参数的使用"></a>timeout参数的使用</h3><p>规定响应时间，超过响应时间的数据不再获取。<br>以秒为单位。<br>可以用来剔除响应时间过长的代理ip。</p><h3 id="retring模块的使用"><a href="#retring模块的使用" class="headerlink" title="retring模块的使用"></a>retring模块的使用</h3><p>由于瞬间的网络波动，导致请求不成，利用该模块，可以多发送几次请求，避免由于瞬间的网络波动导致的请求不成功。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> retrying <span class="keyword">import</span> retry</span><br><span class="line"></span><br><span class="line"><span class="comment">#retry是一个三层函数的嵌套，并且返回了内部函数的引用，是一个有参的修饰器</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Baidu</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.url = <span class="string">&#x27;xxx.com&#x27;</span></span><br><span class="line">        self.num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @retry(<span class="params">stop_max_attempt_number=<span class="number">3</span></span>) </span><span class="comment"># 最大尝试次数3次</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_request</span>(<span class="params">self</span>):</span><br><span class="line">        self.num += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;第<span class="subst">&#123;self.num&#125;</span>次请求&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> requests.get(self.url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.send_request()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    baidu = Baidu()</span><br><span class="line">    baidu.run()</span><br></pre></td></tr></table></figure><h2 id="数据类型介绍"><a href="#数据类型介绍" class="headerlink" title="数据类型介绍"></a>数据类型介绍</h2><h3 id="异步加载动态数据"><a href="#异步加载动态数据" class="headerlink" title="异步加载动态数据"></a>异步加载动态数据</h3><p>url表面没有发生变化的情况下，加载出来其它的数据内容称为动态数据，这是由js实现的，而因此加载出来的动态数据包，都是存在于XHR里。<br>就拿<a href="https://weibo.com/">新浪微博</a>来说，当进行鼠标的向下翻滚的动作时，该网页进行异步请求，每个包内有20条博客信息：<br><img src="/img/crawler02/07.png"></p><h3 id="json数据"><a href="#json数据" class="headerlink" title="json数据"></a>json数据</h3><p>JSON（JavaScript Object Notation）是一种轻量级的数据交换格式。它以易于阅读和编写的文本格式来存储和表示数据，通常用于在不同的系统之间进行数据交换。JSON数据以键-值对的形式组织，可以包含对象、数组、字符串、数字等基本数据类型。它经常在Web开发、API通信等领域被广泛使用。<br>可以发现，鼠标下滚响应的就是josn数据。<br><img src="/img/crawler02/08.png"><br>这里推荐一个解析json语言的网站：<a href="http://www.json.cn/">www.json.cn</a></p><h3 id="新浪微博异步加载数据案例"><a href="#新浪微博异步加载数据案例" class="headerlink" title="新浪微博异步加载数据案例"></a>新浪微博异步加载数据案例</h3><p>经过对一段时间的学习，尝试爬取<a href="https://weibo.com/">新浪微博</a>网站的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url_ = <span class="string">&#x27;https://weibo.com/ajax/feed/hottimeline?refresh=2&amp;group_id=102803&amp;containerid=102803&amp;extparam=discover%7Cnew_feed&amp;max_id=1&amp;count=10&#x27;</span></span><br><span class="line"></span><br><span class="line">    headers_ = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Cookie&#x27;</span>:<span class="string">&#x27;SUB=_2AkMR1GKgf8NxqwFRmfwRymLkZY5zyAvEieKniJN7JRMxHRl-yT9kqhwItRB6OlRMT6f2MRIlVPOctqJxavYph_OL_Sl4; SUBP=0033WrSXqPxfM72-Ws9jqgMF55529P9D9WhhWq.RvQQ9c.LqJFBFB4b8; XSRF-TOKEN=4_g-DVRkdHwRkD9QpCwsgpeo; WBPSESS=Wk6CxkYDejV3DDBcnx2LOQTh3HXmW9PE4h0YFB7m9VnOBZnF4nMfgYiqTGnV-QgF0q5I709Pi0aYBHLczX2dQ5rJfNRPlX6uGeqbnP_VYStcRlnbtBbi_jpy_L_GG9oj&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    response_ = requests.get(url_, headers=headers_)</span><br><span class="line">    str_data = response_.text</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;新浪微博.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(str_data)</span><br></pre></td></tr></table></figure><p><img src="/img/crawler02/09.png"></p><h3 id="数据结构分类"><a href="#数据结构分类" class="headerlink" title="数据结构分类"></a>数据结构分类</h3><p>爬虫爬取的文本数据，一般分为两类：</p><ul><li>结构化数据：结构比较规范，大致包括json、xml。<ul><li>json格式数据的特点：<ul><li>最外层要么是一个列表一样的[]，要么事字典一样的{}</li><li>json数据的引号必须是双引号</li><li>末尾元素，不写逗号</li><li>没有注释<br>  提取json数据的数据，需要一个第三方库：jsonpath</li></ul></li><li>xml结构化特点（极其的少）：<ul><li>与html十分的相像，但结构更为的严谨</li></ul></li></ul></li><li>非结构话数据：html<br> 因为html与xml十分的相像，所用共同用正则表达式、xpath、bs4进行解析<br>  - 正则表达式；效率高，但难度大<br>  - bs4：难度小，但效率低<br>  所以这里我学习的是xpath这种解析方式,在python中通过使用lxml这个库进行实现xpath语法</li></ul><p>html与xml的不同：</p><ul><li>xml是严谨的结构化数据</li><li>xml是数据容器,作用仅仅是保存数据,是一个数据的载体</li><li>html是一种呈现方式</li></ul><h3 id="json格式数据转与python能够处理的数据格式相互转化"><a href="#json格式数据转与python能够处理的数据格式相互转化" class="headerlink" title="json格式数据转与python能够处理的数据格式相互转化"></a>json格式数据转与python能够处理的数据格式相互转化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># python格式数据转换为json格式数据</span></span><br><span class="line">    dict_data = &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;张三&quot;</span>,</span><br><span class="line">        <span class="string">&quot;age&quot;</span>: <span class="number">18</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">print</span>(dict_data,<span class="built_in">type</span>(dict_data)) <span class="comment"># 输出结果 &#123;&#x27;name&#x27;: &#x27;张三&#x27;, &#x27;age&#x27;: 18&#125; &lt;class &#x27;dict&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># dumps是用于对数据的操作，转换是默认使用的是ascii编码,使用ensure_ascii=False用以显示中文，indent用于设置每一个键值对的缩进空格数量，是输出更加美观</span></span><br><span class="line">    json_data = json.dumps(dict_data, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(json_data,<span class="built_in">type</span>(json_data)) <span class="comment"># 在加入ensure_ascii=False之前的输出结果 &#123;&quot;name&quot;: &quot;\u5f20\u4e09&quot;, &quot;age&quot;: 18&#125; &lt;class &#x27;str&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据输出结果发现，python为了方便区分python数据和json数据，python数据所用的是单引号，json数据所用的是双引号。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#dump是用于对json文件的操作</span></span><br><span class="line">    file_obj = <span class="built_in">open</span>(<span class="string">&quot;test.json&quot;</span>,<span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    json.dump(dict_data, file_obj, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># json格式数据转换为python格式数据，才能够处理前端交互过来的json的数据</span></span><br><span class="line">    <span class="comment"># loads是用于对数据的操作</span></span><br><span class="line">    <span class="comment"># python_data = json.loads(json_data)</span></span><br><span class="line">    <span class="comment"># print(python_data,type(python_data)) # 输出结果 &#123;&#x27;name&#x27;: &#x27;张三&#x27;, &#x27;age&#x27;: 18&#125; &lt;class &#x27;dict&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># load是用于对json文件的操作</span></span><br><span class="line">    file_obj = <span class="built_in">open</span>(<span class="string">&quot;test.json&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    python_data = json.load(file_obj)</span><br><span class="line">    <span class="built_in">print</span>(python_data,<span class="built_in">type</span>(python_data)) <span class="comment"># 输出结果 &#123;&#x27;name&#x27;: &#x27;张三&#x27;, &#x27;age&#x27;: 18&#125; &lt;class &#x27;dict&#x27;&gt;</span></span><br><span class="line">    </span><br><span class="line">    file_obj.close()</span><br></pre></td></tr></table></figure><h2 id="json格式提取之jsonpath"><a href="#json格式提取之jsonpath" class="headerlink" title="json格式提取之jsonpath"></a>json格式提取之jsonpath</h2><h3 id="jsonpath"><a href="#jsonpath" class="headerlink" title="jsonpath"></a>jsonpath</h3><p>用来解析多层嵌套的json数据，jsonpath是一种信息抽取类库，是从json文档中抽取指定信息的工具，提供多种语言是西安版本，包括：js、python、PHP、java。</p><h3 id="常用的语法标识"><a href="#常用的语法标识" class="headerlink" title="常用的语法标识"></a>常用的语法标识</h3><ul><li>$：根节点</li><li>@：现行节点</li><li>. or []：取子节点</li><li>..：纵向跨节点</li><li><ul><li>：匹配所有元素节点</li></ul></li><li>[]：迭代器标示（可以在里面做简单的迭代操作）</li><li>[,]：支持迭代器中做多选</li><li>?()：支持过滤操作</li><li>()：支持表达式计算</li></ul><h3 id="尝试使用jsonpath"><a href="#尝试使用jsonpath" class="headerlink" title="尝试使用jsonpath"></a>尝试使用jsonpath</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url_ = <span class="string">&#x27;https://xiaoyuan.lagou.com/api/promotion/getPromotionPosition.json?categoryId=2&#x27;</span></span><br><span class="line">    header_ = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    res = requests.get(url_, headers=header_).json()</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    json()是python的内置函数，可以将获取的json数据直接全部转化成python格式的数据，相当于：</span></span><br><span class="line"><span class="string">    res = res.text</span></span><br><span class="line"><span class="string">    res = json.loads(res)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查询positionName和salary，并以字典的形式返回</span></span><br><span class="line">    path_ = <span class="string">&#x27;$..positionPromotionList[*]&#x27;</span></span><br><span class="line"></span><br><span class="line">    res = jsonpath.jsonpath(res, path_)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> res:</span><br><span class="line">        <span class="built_in">print</span>(i[<span class="string">&#x27;positionName&#x27;</span>], i[<span class="string">&#x27;salary&#x27;</span>])</span><br></pre></td></tr></table></figure><p>总的来说，对于json数据的爬取是以以下流程进行的：</p><ul><li>爬取json数据</li><li>将json数据的数据格式用过json方法或者json模块中loads或者loads方法转换成python的数据格式</li><li>通过jsonpath模块检索所需要的数据</li></ul><h2 id="html格式提取值xpath"><a href="#html格式提取值xpath" class="headerlink" title="html格式提取值xpath"></a>html格式提取值xpath</h2><h3 id="xpath与lxml"><a href="#xpath与lxml" class="headerlink" title="xpath与lxml"></a>xpath与lxml</h3><ul><li>xpath是一门在html\xml文档中查找信息的语言，可以用来在html\xml文档中对元素和属性进行遍历。</li><li>lxml是一款高性能的python html\xml解析器，来快速的定位特定元素以及获取节点信息。</li></ul><h3 id="xpath相较于jsonpath"><a href="#xpath相较于jsonpath" class="headerlink" title="xpath相较于jsonpath"></a>xpath相较于jsonpath</h3><p>xpath和jsonpath的语法相类似，但是jsonpath是个Key-value递归结构，不需要属性访问，也不能对父节点进行访问问，xpath可以访问父节点。<br>在子级的索引方面，也就是[],jsonpath是从0开始索引第一个子级节点的，-1表示最后一个节点，而xpath是从1开始索引第一个子级节点的，last()标识最后一个节点</p><h3 id="xpath中节点选择的工具"><a href="#xpath中节点选择的工具" class="headerlink" title="xpath中节点选择的工具"></a>xpath中节点选择的工具</h3><p>XPath Helper是一款专用于chrome内核浏览器的实用型爬虫网页解析工具（免费）。</p><ul><li>当然还可对查询出的xpath进行编辑，正确编辑的结果将会显示在旁边的结果框，并在网页中高亮显示</li><li>更便于获取网页数据xpath，从而进行网络数据批量爬取<br><img src="/img/crawler02/10.png"><br>最左边填写xpath语法，右边会显示检索到的结果。<br>在用爬虫爬取时，一定要注意抓的包是否正确，因为这个工具时是在整个页面中检索的，相当于是在所有收到的包中进行检索，而我们抓包一般是针对一个包进行操作。</li></ul><h3 id="xpath节点选取语法"><a href="#xpath节点选取语法" class="headerlink" title="xpath节点选取语法"></a>xpath节点选取语法</h3><ul><li>nodename：选中该元素</li><li>&#x2F;：从根节点选取，或者是元素和元素间的过度</li><li>&#x2F;&#x2F;：从匹配选择的当前节点选择文档中的节点，而不考虑他们的位置</li><li>.：选取当前节点</li><li>..：选取当前节点的父节点</li><li>@：选取属性</li><li>text()：选取节点文本</li></ul><h3 id="利用lxml模块实现xpath对html-xml的检索"><a href="#利用lxml模块实现xpath对html-xml的检索" class="headerlink" title="利用lxml模块实现xpath对html\xml的检索"></a>利用lxml模块实现xpath对html\xml的检索</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url_ = <span class="string">&#x27;https://movie.douban.com/subject/27060077/&#x27;</span></span><br><span class="line"></span><br><span class="line">    header_ = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    res = requests.get(url_, headers=header_).text</span><br><span class="line"></span><br><span class="line">    <span class="comment"># str类型无法直接被xpath语法处理，所以需要转化类型</span></span><br><span class="line">    html_obj = etree.HTML(res) <span class="comment"># 结果是一个html对象</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用xpath语法进行检索</span></span><br><span class="line">    path_ = <span class="string">&#x27;//li[@class=&quot;celebrity&quot;]/&#x27;</span> <span class="comment"># 属性的值用的是单引号，所以外围用双引号</span></span><br><span class="line">    list_ = html_obj.xpath(path_ + <span class="string">&quot;a/div/@style&quot;</span>)</span><br><span class="line">    <span class="comment"># print(list_)</span></span><br><span class="line">    list_ = [i.split(<span class="string">&#x27;background-image: url(&#x27;</span>)[<span class="number">1</span>].split(<span class="string">&#x27;)&#x27;</span>)[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> list_]</span><br><span class="line">    <span class="built_in">print</span>(list_)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list_:</span><br><span class="line">        url_ = i</span><br><span class="line">        res = requests.get(url_, headers=header_)</span><br><span class="line">        name = i.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(name, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(res.content)</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要介绍了爬虫的基本概念、数据类型、数据结构分类、json格式数据转与python能够处理的数据格式相互转化、json格式提取之jsonpath、xpath与lxml、xpath节点选取语法、利用lxml模块实现xpath对html\xml的检索。<br>学习到这里已经可以完成基本的抓包和数据提取了，但是爬虫的进阶还需要更深入的学习。</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Crawler </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>爬虫-01</title>
      <link href="/2024/07/05/crawler01/"/>
      <url>/2024/07/05/crawler01/</url>
      
        <content type="html"><![CDATA[<h1 id="爬虫-01"><a href="#爬虫-01" class="headerlink" title="爬虫-01"></a>爬虫-01</h1><p>在经过了解和学前准备之后，就要开启真正的爬虫之旅了。</p><h2 id="http协议以及请求头的介绍"><a href="#http协议以及请求头的介绍" class="headerlink" title="http协议以及请求头的介绍"></a>http协议以及请求头的介绍</h2><h3 id="网络请求的发送和响应接收"><a href="#网络请求的发送和响应接收" class="headerlink" title="网络请求的发送和响应接收"></a>网络请求的发送和响应接收</h3><p><img src="/img/crawler01/01.png"></p><ul><li>电脑通过浏览器将域名发送给DNS服务器。</li><li>DNS服务器将域名解析成IP地址返还给电脑。（每一个IP地址指定特定的一台电脑或者服务器）</li><li>电脑通过IP地址访问目的服务器所在的地址。</li><li>目的服务武器返回数据给电脑。</li></ul><h3 id="http与https协议"><a href="#http与https协议" class="headerlink" title="http与https协议"></a>http与https协议</h3><p><img src="/img/crawler01/02.png"><br>当我们向服务器请求数据的时候，需要遵循http协议，https协议，这是一种默认的规则。<br>当我们向服务器请求数据的时候，需要某些信息的记录，才能拿到数据。<br>https相较于http多了一层加密，优点是更加安全，缺点是效率受影响。</p><h3 id="数据包"><a href="#数据包" class="headerlink" title="数据包"></a>数据包</h3><p>当我们访问网站时，网站返回我们数据包，其主要内容如下：</p><ul><li>Headers：请求信息request、响应信息response。</li><li>Preview：预览效果。</li><li>Response：数据包的类型时html，里面放的是这个html的源代码。</li></ul><p>其中对我们比较重要的是Headers，其内容有：</p><ul><li>General：整体的信息描述。<ul><li>Request URL：该数据包对应的域名。</li><li>Request Method：请求方式 GET POST。</li><li>Status Code：状态码，用来描述请求结果的。</li><li>Remote ADDress：ip:端口号。</li></ul></li><li>Response Headers（响应头）：响应信息服务需要遵循这种股则协议，浏览器才能解析，并且展示。</li><li>Request Headers：<ul><li>Accept：我们接受哪些数据类型。</li><li>Accept-Encoding：浏览器接受的编码类型。</li><li>Accept-Language：接受语言。</li><li>Connection：长连接。</li><li>Cookie：记录会话信息，包含用户名和服务器的交流信息，身份信息，具体表现有下次访问不用填写账号密码。</li><li>Host：主机地址 域名 url。</li><li>User-Agent：记录客户端的信息，用户代理。</li></ul></li></ul><h3 id="字符编码"><a href="#字符编码" class="headerlink" title="字符编码"></a>字符编码</h3><p>我们使用python向服务器发送请求，需要将python数据类型转换成字节类型（编码），才能在网络上传输，而服务器返回的数据的数据类型是字节类型，要使我们能看懂，需要转换成python数据类型（解码）。</p><ul><li>encode：python数据类型  &gt;&gt; bytes类型</li><li>decode：bytes类型 &gt;&gt; python数据类型<br>注：编码格式要和解码格式保持一致，其中默认值都为’utf-8’。</li></ul><h2 id="requests库"><a href="#requests库" class="headerlink" title="requests库"></a>requests库</h2><h3 id="requests库的下载"><a href="#requests库的下载" class="headerlink" title="requests库的下载"></a>requests库的下载</h3><p>我么可以通过这个库进行浏览器的模拟去访问服务器，但是是第三方模块，所以需要我们进行下载：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">workon pachong</span><br><span class="line">pip install requests</span><br></pre></td></tr></table></figure><h3 id="requests库的使用"><a href="#requests库的使用" class="headerlink" title="requests库的使用"></a>requests库的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入发送网络请求的requests库</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># requests库封装了urllib3库，使得我们使用起来更加方便</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 确认目标url</span></span><br><span class="line">    url_ = <span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 发送网络请求，获取响应</span></span><br><span class="line">    response_ = requests.get(url_) <span class="comment"># 目标url,利用requests库发送的网络请求，最终得到一个响应对象response</span></span><br><span class="line">    <span class="built_in">print</span>(response_)</span><br><span class="line">    <span class="built_in">print</span>(response_.encoding) <span class="comment"># 打印响应的编码格式，就是text属性自动检测到的编解码格式</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(response_.text)  #打印响应的文本数据</span></span><br><span class="line">    <span class="comment"># print(type(response_.text))  #string</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(response_.content)  #打印响应的文本数据</span></span><br><span class="line">    <span class="comment"># print(type(response_.content))  #bytes</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存数据</span></span><br><span class="line">    <span class="comment"># with open(&#x27;baidu01.html&#x27;,&#x27;w&#x27;,encoding=&#x27;utf-8&#x27;) as f: # 由于response_.text是字符串类型，所以直接写入即可</span></span><br><span class="line">    <span class="comment"># # 写入数据时遇到UnicodeEncodeError，加上encoding = &#x27;utf-8&#x27;即可</span></span><br><span class="line">    <span class="comment">#     f.write(response_.text) #保存的数据出现乱码，是因为从网络请求拿下来的数据都是字节类型，而响应对象的text属性是字符串类型，是因为text会自动识别编码格式，但不一定准确，解码错误就会出现乱码，所以一般直接使用响应对象的content属性，因为content属性是字节类型，可以自己指定编码格式，一般指定utf-8</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;baidu02.html&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># wb二进制方法写入的话，不需要加encoding=&#x27;utf-8&#x27;</span></span><br><span class="line">        f.write(response_.content)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pycharm直接打开本地html文件，会自动熏染，自动请求某些需要的部分</span></span><br><span class="line">    <span class="comment"># 通过终端打开本地html文件，不会自动渲染，需要手动请求，start html文件路径</span></span><br></pre></td></tr></table></figure><h3 id="响应对象response里的其它属性"><a href="#响应对象response里的其它属性" class="headerlink" title="响应对象response里的其它属性"></a>响应对象response里的其它属性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    response = requests.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 响应体</span></span><br><span class="line">    <span class="built_in">print</span>(response.text)</span><br><span class="line">    <span class="built_in">print</span>(response.content)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 响应状态码</span></span><br><span class="line">    <span class="built_in">print</span>(response.status_code)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 响应对应的请求头</span></span><br><span class="line">    <span class="built_in">print</span>(response.request.headers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 响应头</span></span><br><span class="line">    <span class="built_in">print</span>(response.headers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 响应对应请求的cookie</span></span><br><span class="line">    <span class="built_in">print</span>(response.request._cookies)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 响应的cookie</span></span><br><span class="line">    <span class="built_in">print</span>(response.cookies)</span><br></pre></td></tr></table></figure><p><img src="/img/crawler01/03.png"></p><h3 id="用户代理"><a href="#用户代理" class="headerlink" title="用户代理"></a>用户代理</h3><p>因为我们直接访问网站会被发现是爬虫，获取的数据有所缺少，为我们需要通过用户代理获取正确的数据。<br>对于服务端来说，是一个反爬点，对于我们来说，它是模拟正常正常用户的其中一个部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">    response = requests.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>, headers=headers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;baidu03.html&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(response.content)</span><br></pre></td></tr></table></figure><h2 id="URL传参"><a href="#URL传参" class="headerlink" title="URL传参"></a>URL传参</h2><h3 id="User-Agent池"><a href="#User-Agent池" class="headerlink" title="User-Agent池"></a>User-Agent池</h3><p>当我们需要短时间内连续多次访问一个服务器，服务器会记录我们的每一次访问，当服务器发现访问的是同一个User-Agent，会被判为我们是爬虫程序，可能会禁止我们的访问。<br>解决办法，使用User-Agent池，每次请求都从UA池中随机拿一个身份进行请求。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">ua_list = [<span class="string">&#x27;Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;User-Agent:Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;User-Agent:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;User-Agent:Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;User-Agent:Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;User-Agent:Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;User-Agent:Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11&#x27;</span></span><br><span class="line">           ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_ua</span>():</span><br><span class="line">    header = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: random.choice(ua_list)&#125;</span><br><span class="line">    <span class="keyword">return</span> header</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(get_ua())</span><br><span class="line">    url_ = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line">    response = requests.get(url_, get_ua())</span><br><span class="line">    <span class="built_in">print</span>(response.request.headers)</span><br></pre></td></tr></table></figure><p>这里我还写了一个随机函数，会每次调用随机从ua池中选择一个ua，提升了代码的复用性。</p><h3 id="URL传参-1"><a href="#URL传参-1" class="headerlink" title="URL传参"></a>URL传参</h3><p>根据数据包的分析，发现每个图片都是单独的数据包，在接收到html的主框架后，浏览器发现有许因该放着图片的地方，放的是图片的url，此时浏览器就会拿着图片的url自动去发送网络请求，进行图片的填充，最终呈现完整的图片。<br>在url中，自？之后的都是参数，以键值对的方式存在，’&#x3D;’连接键与值，两个键值对之间用’&amp;’连接。而且只有部分键值对是必须的。<br>中文传参并不友好方便，会经过浏览器的解析在发送给服务器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote,unquote</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    input_wd = <span class="built_in">input</span>(<span class="string">&#x27;请输入要搜索的内容：&#x27;</span>)</span><br><span class="line">    wd = quote(input_wd)</span><br><span class="line">    <span class="comment"># 编码格式符合 URL编码解码格式</span></span><br><span class="line">    <span class="comment"># print(wd) # %E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;User-Agent:Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 方法一:</span></span><br><span class="line">    <span class="comment"># url_ = f&#x27;https://www.baidu.com/s?wd=&#123;wd&#125;&#x27;</span></span><br><span class="line">    <span class="comment"># response = requests.get(url_, headers=headers)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 方法二:</span></span><br><span class="line">    url_ = <span class="string">&#x27;https://www.baidu.com/s?&#x27;</span></span><br><span class="line">    params_ = &#123;</span><br><span class="line">       <span class="string">&#x27;wd&#x27;</span>: input_wd</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.get(url_, headers=headers, params=params_)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;baidu.html&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(response.content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一旦出现&#x27;百度安全验证&#x27;说明已经被反爬了。</span></span><br></pre></td></tr></table></figure><h2 id="贴吧案例"><a href="#贴吧案例" class="headerlink" title="贴吧案例"></a>贴吧案例</h2><p>使用面向对象完成贴吧翻页爬取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TieBa</span>:</span><br><span class="line">    <span class="comment"># 初始化方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.url_ = <span class="string">&#x27;https://tieba.baidu.com/f?&#x27;</span></span><br><span class="line">        self.headers_ = &#123;</span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 发送请求，得到响应对象</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_request</span>(<span class="params">self, params_</span>):</span><br><span class="line">        response_ = requests.get(self.url_, headers=self.headers_, params=params_)</span><br><span class="line">        str_data = response_.content.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> str_data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存数据            页数  内容       标题</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">self, page, str_data, data_</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&#x27;<span class="subst">&#123;data_&#125;</span>_<span class="subst">&#123;page+<span class="number">1</span>&#125;</span>.html&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(str_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调度方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        data_ = <span class="built_in">input</span>(<span class="string">&#x27;请输入要搜索的内容：&#x27;</span>)</span><br><span class="line">        pages_ = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入要爬取的页数：&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 循环爬取多页</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(pages_):</span><br><span class="line">            params_ = &#123;</span><br><span class="line">                <span class="string">&#x27;kw&#x27;</span>: data_,</span><br><span class="line">                <span class="string">&#x27;pn&#x27;</span>: page * <span class="number">50</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            str_data =  self.send_request(params_)</span><br><span class="line"></span><br><span class="line">            self.save_data(page, str_data, data_)</span><br><span class="line">            time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tieba = TieBa()</span><br><span class="line">    tieba.run()</span><br></pre></td></tr></table></figure><h2 id="网易云案例"><a href="#网易云案例" class="headerlink" title="网易云案例"></a>网易云案例</h2><h3 id="非VIP的爬取"><a href="#非VIP的爬取" class="headerlink" title="非VIP的爬取"></a>非VIP的爬取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url_ = <span class="string">&#x27;https://m701.music.126.net/20240705095240/c4e8c9533fbc86da0341845a988fb336/jdyyaac/obj/w5rDlsOJwrLDjj7CmsOj/44283587460/8809/cd66/6324/890ff412f637c908a7986b9fac0538b1.m4a&#x27;</span></span><br><span class="line"></span><br><span class="line">headers_ = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.1528.49&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(url_, headers=headers_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在爬取图片、音频或者视频数据时，是将其字节数据进行保存</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;二十二.mp3&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(response.content)</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里，爬虫的基本知识就介绍完了，主要是对http协议、请求头、字符编码、requests库、URL传参。<br>尝试过贴吧案例和网易云案例，基本掌握了爬虫的基本操作。</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Crawler </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>爬虫-基础与学前准备</title>
      <link href="/2024/07/04/Crawler/"/>
      <url>/2024/07/04/Crawler/</url>
      
        <content type="html"><![CDATA[<h1 id="爬虫-基础与学前准备"><a href="#爬虫-基础与学前准备" class="headerlink" title="爬虫-基础与学前准备"></a>爬虫-基础与学前准备</h1><h2 id="爬虫基本介绍"><a href="#爬虫基本介绍" class="headerlink" title="爬虫基本介绍"></a>爬虫基本介绍</h2><p>网络爬虫（又被称为网页蜘蛛，网络机器人）就是模拟浏览器发送网络请求，接收请求响应，一种按照一定的规则，自动地抓取互联网信息的程序。</p><p>原则上,只要是浏览器(客户端)能做的事情，爬虫都能够做。</p><ul><li>爬虫：模拟客户端访问，抓取数据。</li><li>反爬：保护重要数据，阻止恶意网络攻击。</li><li>反反爬：针对反爬做的措施。</li></ul><h3 id="爬虫分类"><a href="#爬虫分类" class="headerlink" title="爬虫分类"></a>爬虫分类</h3><ul><li>通用爬虫：通过搜索引擎和大型Web服务提供商的爬虫</li><li>聚焦爬虫：针对特定网站的爬虫，定向的获取某方面数据的爬虫。</li></ul><p>聚焦爬虫又主要分为：累计式爬虫、增量式爬虫、Deep web爬虫（深层网络爬虫）。</p><h3 id="爬虫基本流程"><a href="#爬虫基本流程" class="headerlink" title="爬虫基本流程"></a>爬虫基本流程</h3><p><img src="/img/Crawler/01.jpg"></p><ul><li>向起始url发送请求，，并获取相应。</li><li>对响应进行提取。</li><li>如果提取数据，则1将数据进行保存。</li><li>如果提取url，则继续发送请求获取响应。</li></ul><h3 id="rorbots协议"><a href="#rorbots协议" class="headerlink" title="rorbots协议"></a>rorbots协议</h3><p>网站通过robots协议告诉搜索引擎哪些页面可以抓取。<br><img src="/img/Crawler/02.png"></p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>初次接触爬虫部分的学习，习惯性创建一个虚拟环境负责这部分的学习。</p><h3 id="安装-mod"><a href="#安装-mod" class="headerlink" title="安装 mod"></a>安装 mod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i virtualenvwrapper-win</span><br></pre></td></tr></table></figure><h3 id="创建目录存放虚拟环境"><a href="#创建目录存放虚拟环境" class="headerlink" title="创建目录存放虚拟环境"></a>创建目录存放虚拟环境</h3><p>略</p><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>以 WORKON_HOME 为名，值选择一个目录，以后所有使用virtualenvwrapper管理的虚拟环境都会在这个目录中。</p><p><img src="/img/Crawler/03.png"></p><h3 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkvirtualenv path(python的路径，如：C:\environment\Python3.10\python.exe) 虚拟环境名</span><br></pre></td></tr></table></figure><h3 id="删除虚拟环境"><a href="#删除虚拟环境" class="headerlink" title="删除虚拟环境"></a>删除虚拟环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rmvirtualenv 虚拟环境名</span><br></pre></td></tr></table></figure><h3 id="列出虚拟环境"><a href="#列出虚拟环境" class="headerlink" title="列出虚拟环境"></a>列出虚拟环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lsvirtualenv</span><br><span class="line">或者</span><br><span class="line">workon</span><br></pre></td></tr></table></figure><p><img src="/img/Crawler/04.png"></p><h3 id="激活虚拟环境"><a href="#激活虚拟环境" class="headerlink" title="激活虚拟环境"></a>激活虚拟环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">workon 虚拟环境名</span><br></pre></td></tr></table></figure><h2 id="软件准备"><a href="#软件准备" class="headerlink" title="软件准备"></a>软件准备</h2><p>这里我学习使用的是谷歌浏览器和pycharm。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里，我们已经对爬虫有所了解，学习了如何使用python搭建虚拟环境，并且做好学习爬虫的准备事项了。</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Crawler </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sass</title>
      <link href="/2024/05/14/sass/"/>
      <url>/2024/05/14/sass/</url>
      
        <content type="html"><![CDATA[<h1 id="Sass-基础"><a href="#Sass-基础" class="headerlink" title="Sass 基础"></a>Sass 基础</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Sass 是一个 CSS 预处理器。<br>Sass 扩展了 CSS3，增加了规则、变量、混入、选择器、继承、内置函数等等特性。<br>Sass 生成良好格式化的 CSS 代码，易于组织和维护。<br>Sass 完全兼容所有版本的 CSS。<br>Sass 文件后缀为 .scss。</p><p>简单来说 Sass 可以让我们以一种更灵活更有效的方式去写 css 的样式。</p><h2 id="初次尝试"><a href="#初次尝试" class="headerlink" title="初次尝试"></a>初次尝试</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install sass -g</span><br></pre></td></tr></table></figure><p>因为 Ruby-sass 和 node-sass 已经是历史了，所以这里我们安装的是 dart-sass。<br>下载之后可以用下载命令检查 sass 的版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sass --version</span><br></pre></td></tr></table></figure><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>浏览器并不支持 Sass 代码。因此，你需要使用一个 Sass 预处理器将 Sass 代码转换为 CSS 代码。<br>我们可以编辑一个 text.scss 文件，内容如下：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 定义变量与值 */</span></span><br><span class="line"><span class="variable">$bgcolor</span>: lightblue;</span><br><span class="line"><span class="variable">$textcolor</span>: darkblue;</span><br><span class="line"><span class="variable">$fontsize</span>: <span class="number">18px</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 使用变量 */</span></span><br><span class="line"><span class="selector-tag">body</span> &#123;</span><br><span class="line">  <span class="attribute">background-color</span>: <span class="variable">$bgcolor</span>;</span><br><span class="line">  <span class="attribute">color</span>: <span class="variable">$textcolor</span>;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="variable">$fontsize</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们已经看到了 scss 中的定义变量，是以 $variablename: value; 的形式进行赋值的。<br>接着我们在文件所在文件夹打开终端，运行以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sass text.scss text.css</span><br></pre></td></tr></table></figure><p>这条命令会告诉 Sass 编译器将 text.scss 文件编译成 text.css 文件，同时生成一个源映射（source map）文件 text.css.map，这个源映射文件用于调试，允许开发者追踪 CSS 规则回对应的 .scss 文件。</p><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><h4 id="变量属性"><a href="#变量属性" class="headerlink" title="变量属性"></a>变量属性</h4><p>前面我们已经了解过如何定义变量了，接下来我们了解一下变量的其它内容。<br>Sass 变量可以存储以下信息：</p><ul><li>字符串</li><li>数字</li><li>颜色值</li><li>布尔值</li><li>列表</li><li>null 值</li></ul><h4 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h4><p>作用域方面，Sass 变量的作用域只能在当前的层级上有效果。<br>当然 Sass 中我们可以使用 !global 关键词来设置变量是全局的。</p><p>注意：所有的全局变量我们一般定义在同一个文件，如：_globals.scss，然后我们使用 @import “globals”;  来包含该文件。</p><h3 id="Sass-嵌套规则与属性"><a href="#Sass-嵌套规则与属性" class="headerlink" title="Sass 嵌套规则与属性"></a>Sass 嵌套规则与属性</h3><h4 id="嵌套"><a href="#嵌套" class="headerlink" title="嵌套"></a>嵌套</h4><p>Sass 嵌套 CSS 选择器类似于 HTML 的嵌套规则。<br>如下我们嵌套一个导航栏的样式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">nav &#123;</span><br><span class="line">  ul &#123;</span><br><span class="line">    margin: 0;</span><br><span class="line">    padding: 0;</span><br><span class="line">    list-style: none;</span><br><span class="line">  &#125;</span><br><span class="line">  li &#123;</span><br><span class="line">    display: inline-block;</span><br><span class="line">  &#125;</span><br><span class="line">  a &#123;</span><br><span class="line">    display: block;</span><br><span class="line">    padding: 6px 12px;</span><br><span class="line">    text-decoration: none;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h4><p>很多 CSS 属性都有同样的前缀，例如：font-family, font-size 和 font-weight ， text-align, text-transform 和 text-overflow。<br>在 Sass 中，我们可以使用嵌套属性来编写它们：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">font: &#123;</span><br><span class="line">  family: Helvetica, sans-serif;</span><br><span class="line">  size: 18px;</span><br><span class="line">  weight: bold;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">text: &#123;</span><br><span class="line">  align: center;</span><br><span class="line">  transform: lowercase;</span><br><span class="line">  overflow: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Sass-import"><a href="#Sass-import" class="headerlink" title="Sass @import"></a>Sass @import</h3><h4 id="import"><a href="#import" class="headerlink" title="@import"></a>@import</h4><p>类似 CSS，Sass 支持 @import 指令。<br>@import 指令可以让我们导入其他文件等内容。<br>CSS @import 指令在每次调用时，都会创建一个额外的 HTTP 请求。但，Sass @import 指令将文件包含在 CSS 中，不需要额外的 HTTP 请求。<br>Sass @import 指令语法如下：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">@import</span> filename;</span><br></pre></td></tr></table></figure><p>注：包含文件时不需要指定文件后缀，Sass 会自动添加 .scss 后缀。</p><h5 id="Sass-Partials"><a href="#Sass-Partials" class="headerlink" title="Sass Partials"></a>Sass Partials</h5><p>除此之外，部分文件（Sass Partials）这个特性可以允许我们将我们的样式分成多个文件，使得我们的样式表更加模块化和组织化。部分文件通常包含不会直接生成 CSS 文件的样式代码，而是被其他 Sass 文件导入使用。<br>部分文件通过在文件名前添加一个下划线（_）来表示，例如 _variables.scss、_mixins.scss 等。Sass 编译器在编译时会忽略以下划线开头的文件，这意味着它们不会被编译成对应的 CSS 文件。相反，它们设计为被其他 Sass 文件导入。</p><h3 id="Sass-mixin-与-include"><a href="#Sass-mixin-与-include" class="headerlink" title="Sass @mixin 与 @include"></a>Sass @mixin 与 @include</h3><blockquote><p>@mixin 指令允许我们定义一个可以在整个样式表中重复使用的样式。<br>@include 指令可以将混入（mixin）引入到文档中。</p></blockquote><h4 id="定义混入"><a href="#定义混入" class="headerlink" title="定义混入"></a>定义混入</h4><p>我们通过 @mixin name {} 来创建一个名为 “name” 的混入。</p><p>注意：Sass 的连接符号 - 与下划线符号 _ 是相同的，也就是 @mixin important-text { } 与 @mixin important_text { } 是一样的混入。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">@mixin</span> important-text &#123;</span><br><span class="line">  <span class="attribute">color</span>: red;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">25px</span>;</span><br><span class="line">  <span class="attribute">font-weight</span>: bold;</span><br><span class="line">  <span class="attribute">border</span>: <span class="number">1px</span> solid blue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="使用混入"><a href="#使用混入" class="headerlink" title="使用混入"></a>使用混入</h4><p>@include 指令可用于包含一混入：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">selector &#123;</span><br><span class="line">  <span class="keyword">@include</span> mixin-name;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，混入中也可以包含混入。</p><h4 id="向混入传递变量"><a href="#向混入传递变量" class="headerlink" title="向混入传递变量"></a>向混入传递变量</h4><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 混入接收两个参数 */</span></span><br><span class="line"><span class="keyword">@mixin</span> bordered(<span class="variable">$color</span>, <span class="variable">$width</span>) &#123;</span><br><span class="line">  <span class="attribute">border</span>: <span class="variable">$width</span> solid <span class="variable">$color</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.myArticle</span> &#123;</span><br><span class="line">  <span class="keyword">@include</span> bordered(blue, <span class="number">1px</span>);  <span class="comment">// 调用混入，并传递两个参数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.myNotes</span> &#123;</span><br><span class="line">  <span class="keyword">@include</span> bordered(red, <span class="number">2px</span>); <span class="comment">// 调用混入，并传递两个参数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>混入和函数可以接受多个参数，用 … 来设置可变参数。</p><h3 id="Sass-extend-与-继承"><a href="#Sass-extend-与-继承" class="headerlink" title="Sass @extend 与 继承"></a>Sass @extend 与 继承</h3><p>@extend 指令告诉 Sass 一个选择器的样式从另一选择器继承。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-class">.button-basic</span>  &#123;</span><br><span class="line">  <span class="attribute">border</span>: none;</span><br><span class="line">  <span class="attribute">padding</span>: <span class="number">15px</span> <span class="number">30px</span>;</span><br><span class="line">  <span class="attribute">text-align</span>: center;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">  <span class="attribute">cursor</span>: pointer;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.button-report</span>  &#123;</span><br><span class="line">  <span class="keyword">@extend</span> .button-basic;</span><br><span class="line">  <span class="attribute">background-color</span>: red;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.button-submit</span>  &#123;</span><br><span class="line">  <span class="keyword">@extend</span> .button-basic;</span><br><span class="line">  <span class="attribute">background-color</span>: green;</span><br><span class="line">  <span class="attribute">color</span>: white;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Sass-函数"><a href="#Sass-函数" class="headerlink" title="Sass 函数"></a>Sass 函数</h3><h4 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h4><p>Sass 定义了各种类型的函数，这些函数我们可以通过 CSS 语句直接调用。</p><h4 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h4><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">@function</span> name(<span class="variable">$value</span>) &#123;</span><br><span class="line">  <span class="keyword">@return</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
            <tag> css </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Webpack 初探</title>
      <link href="/2024/05/11/webpack/"/>
      <url>/2024/05/11/webpack/</url>
      
        <content type="html"><![CDATA[<h1 id="初始-Webpack"><a href="#初始-Webpack" class="headerlink" title="初始 Webpack"></a>初始 Webpack</h1><p>Webpack  是一个前端资源加载&#x2F;打包工具。它将根据模块的依赖关系进行静态分析，然后将这些模块按照指定的规则生成对应的静态资源。</p><p><img src="/img/webpack/webpack.png" alt="img"></p><h2 id="安装-Webpack"><a href="#安装-Webpack" class="headerlink" title="安装 Webpack"></a>安装 Webpack</h2><p>注：本地环境需要支持 <a href="https://nodejs.org/en">node.js</a><br>使用npm安装webpack：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install webpack webpack-cli -g</span><br></pre></td></tr></table></figure><ul><li>webpack：一个模块打包工具</li><li>webpack-cli：是它的命令行工具，允许你从命令行运行 webpack。</li></ul><h2 id="尝试使用-Webpack"><a href="#尝试使用-Webpack" class="headerlink" title="尝试使用 Webpack"></a>尝试使用 Webpack</h2><p>创建一个项目，并进入项目</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir project </span><br><span class="line">cd project</span><br></pre></td></tr></table></figure><p>初始化项目</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm init</span><br></pre></td></tr></table></figure><p>可以直接在项目的根目录下打开终端执行以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm add webpack webpack-cli --save-dev</span><br></pre></td></tr></table></figure><p>这些包会被安装在当前项目的 node_modules 目录下，并且它们的记录会被添加到 package.json 文件的 devDependencies 部分。这样做通常是因为这些包只在开发阶段需要，比如进行项目构建或测试，而不需要在生产环境中。</p><p>使用 vscod 打开当前目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code ./</span><br></pre></td></tr></table></figure><p>创建文件 &#x2F;src&#x2F;data.js</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">function</span> <span class="title function_">getBlogPosts</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> [<span class="string">&quot;POST 1&quot;</span>, <span class="string">&quot;POST 2&quot;</span>, <span class="string">&quot;POST 3&quot;</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建文件 &#x2F;src&#x2F;index.js ，内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import &#123; getBlogPosts &#125; from &#x27;./data&#x27;</span><br><span class="line"></span><br><span class="line">console.log(getBlogPosts())</span><br></pre></td></tr></table></figure><p>创建文件 &#x2F;index.html</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Hello Webpack<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;./src/index.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>进行打包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npx webpack</span><br></pre></td></tr></table></figure><p>项目中会生成 &#x2F;dist&#x2F;main.js 文件，这样就完成了一个简单的打包。</p><p>但在打包工程中会有如下警告，这是因为webpack官方在4中新增了： mode 配置选项，告知 webpack 使用相应模式的内置优化。可配置的值是production、development 和 none，默认为production。<br><img src="/img/webpack/01.png" alt="warning"></p><h2 id="配置-Webpck"><a href="#配置-Webpck" class="headerlink" title="配置 Webpck"></a>配置 Webpck</h2><p>创建 &#x2F;webpack.config.js 文件，其内容如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">&quot;path&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">    <span class="attr">mode</span>: <span class="string">&quot;development&quot;</span>,</span><br><span class="line">    <span class="attr">entry</span>: <span class="string">&quot;./src/index.js&quot;</span>,</span><br><span class="line">    <span class="attr">output</span>: &#123;</span><br><span class="line">        <span class="attr">filename</span>: <span class="string">&quot;test.js&quot;</span>,</span><br><span class="line">        <span class="attr">path</span>: path.<span class="title function_">resolve</span>(__dirname + <span class="string">&quot;/dist&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>mode: “development”：设置构建模式为开发模式。Webpack 还支持 production 模式，用于生产环境的构建。</li><li>entry: “.&#x2F;src&#x2F;index.js”：指定入口文件为 src 目录下的 index.js 文件。Webpack 会从这个文件开始，递归地构建一个依赖图，包含所有需要的模块。</li><li>output: { … }：配置输出选项。<ul><li>filename: “test.js”：设置输出文件的名称为 test.js。</li><li>path: path.resolve(__dirname + “&#x2F;dist”)：设置输出文件存放的路径为当前目录下的 dist 目录。__dirname 是 Node.js 中的一个全局变量，表示当前文件所在的目录。</li></ul></li></ul><p>再次打包后，文件就打包好的文件位置就是 &#x2F;dist&#x2F;test.js<br>当我们尝试编写 css 文件，并进行打包时，会有以下报错：<br><img src="/img/webpack/02.jpg" alt="image-20240511100739299"></p><p>这个报错是在提醒我们可能需要安装 style-loader css-loader 两个 loader。<br>在项目中添加这两个 loader</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm add --save-dev stystyle-loader css-loader</span><br></pre></td></tr></table></figure><p>在 &#x2F;webpack.config.js 中进行配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">module.exports = &#123;</span><br><span class="line">    module: &#123;</span><br><span class="line">            rules: [</span><br><span class="line">                &#123;</span><br><span class="line">                    test: /\.css$/i,</span><br><span class="line">                    use: [&quot;style-loader&quot;,&quot;css-loader&quot;]</span><br><span class="line">                &#125;,&#123;</span><br><span class="line">                    test: /\.(png|jpe?g|gif|svg)$/i,</span><br><span class="line">                    type: &quot;asset/resource&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>test：用来匹配文件</p></li><li><p>use：所匹配的文件所用到的loader</p></li><li><p>type：所用的为 webpack 内置的 loader</p></li></ul><h2 id="在webpack中使用插件"><a href="#在webpack中使用插件" class="headerlink" title="在webpack中使用插件"></a>在webpack中使用插件</h2><h3 id="html-webpack-plugin"><a href="#html-webpack-plugin" class="headerlink" title="html-webpack-plugin"></a>html-webpack-plugin</h3><p>让打包时自动生成 html 文件 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm add html-webpack-plugin --save-dev</span><br></pre></td></tr></table></figure><p>配置 webpack.config.js </p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title class_">HtmlWebpackPlugin</span> = <span class="built_in">require</span>(<span class="string">&quot;html-webpack-plugin&quot;</span>);</span><br><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">    <span class="attr">plugins</span>: [<span class="keyword">new</span> <span class="title class_">HtmlWebpackPlugin</span>(&#123;</span><br><span class="line">    <span class="attr">title</span>: <span class="string">&quot;Webpack Test&quot;</span></span><br><span class="line">    &#125;)]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再运行打包程序后，&#x2F;dist&#x2F;index.html 就为自动生成的页面</p><h3 id="打包符合-ES6-标准的-JS-文件"><a href="#打包符合-ES6-标准的-JS-文件" class="headerlink" title="打包符合 ES6 标准的 JS 文件"></a>打包符合 ES6 标准的 JS 文件</h3><p>在开发前端项目时，我们时常使用到新版本的 JS 特性，但要兼容低版本的浏览器，可以用 babel 这个工具转译我们的 JS 代码。<br>添加 webpack 中的 loader：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm add --save-dev babel-loader @babel/core @babel/preset-env</span><br></pre></td></tr></table></figure><p>webpack.config.js 中的配置：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line"><span class="attr">devtool</span>: <span class="string">&quot;inline-source-map&quot;</span>,</span><br><span class="line"><span class="attr">module</span>: &#123;</span><br><span class="line"><span class="attr">rules</span>:[</span><br><span class="line">&#123;<span class="attr">test</span>: <span class="regexp">/\.js$/</span>,</span><br><span class="line">                <span class="attr">exclude</span>: <span class="regexp">/node_modules/</span>,</span><br><span class="line">                <span class="attr">use</span>: &#123;</span><br><span class="line">                    <span class="attr">loader</span>: <span class="string">&quot;babel-loader&quot;</span>,</span><br><span class="line">                    <span class="attr">options</span>: &#123;</span><br><span class="line">                        <span class="attr">presets</span>: [<span class="string">&quot;@babel/preset-env&quot;</span>]</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再次打包文件后，js 文件按照 ES6 的标准打包。</p><h3 id="压缩文件"><a href="#压缩文件" class="headerlink" title="压缩文件"></a>压缩文件</h3><p>压缩 JS 文件的体积，需要用到 terser-webpack-plugin 的插件，首先先安装一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm add terser-webpack-plugin --save-dev</span><br></pre></td></tr></table></figure><p>并在 webpack.config.js 中配置一下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title class_">TerserPlugin</span> = <span class="built_in">require</span>(<span class="string">&quot;terser-webpack-plugin&quot;</span>);</span><br><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line"><span class="attr">optimization</span>: &#123;</span><br><span class="line">        <span class="attr">minimize</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">minimizer</span>: [<span class="keyword">new</span> <span class="title class_">TerserPlugin</span>()],</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>打包后发现 JS 文件的空格都去掉了，并且变量名都是简化的形式，文件的最后是图片被压缩成 base64。</p><h3 id="webpack-dev-server"><a href="#webpack-dev-server" class="headerlink" title="webpack-dev-server"></a>webpack-dev-server</h3><p>目前为止，我们每次改动都需要重新打包，而 wabpack-dev-server 这个工具可以帮助我们省去这个步骤。<br>安装 wabpack-dev-server：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm add --save-dev webpack-dev-server</span><br></pre></td></tr></table></figure><p>配置 webpack.config.js：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line"><span class="attr">devServer</span>: &#123;</span><br><span class="line">        <span class="attr">static</span>: <span class="string">&quot;./dist&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为了方便我们的打包，可以在 package.json 中进行配置：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;scripts&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;start&quot;</span><span class="punctuation">:</span> <span class="string">&quot;webpack serve --open&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>这是，在终端输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm start</span><br></pre></td></tr></table></figure><p>就可以打包并打开浏览器。</p><h3 id="代码分割"><a href="#代码分割" class="headerlink" title="代码分割"></a>代码分割</h3><p>虽然打包的文件名是一样的，但是浏览器会对每次打开的页面进行缓存，如果不更新文件名，浏览器可能不更新，为了避免浏览器缓存，我们会给文件名加上一串随机的字符，每次更新之后都改为新的字符。webpack 也提供在打包后生成一段新的字符。<br>在 webpack.json.js 中配置：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">    <span class="attr">output</span>: &#123;</span><br><span class="line">        <span class="attr">filename</span>: <span class="string">&quot;[name].[contenthash].js&quot;</span>,</span><br><span class="line">        <span class="attr">path</span>: path.<span class="title function_">resolve</span>(__dirname + <span class="string">&quot;/dist&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="路径别名"><a href="#路径别名" class="headerlink" title="路径别名"></a>路径别名</h3><p>有时候 JS 所在文件的路径嵌套比较深，要引入其他目录下的 JS 比较麻烦，webpack可以让我们指定一个路径别名。<br>在 webpack.json.js 中配置：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">    <span class="attr">resolve</span>: &#123;</span><br><span class="line">        <span class="attr">alias</span>: &#123;</span><br><span class="line">            <span class="attr">utils</span>: path.<span class="title function_">resolve</span>(__dirname + <span class="string">&quot;/src/utils/&quot;</span>),</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就可以用路径 “utils&#x2F;“ 表示 路径 “&#x2F;src&#x2F;utils&#x2F;“。</p><h3 id="webpack-bundle-analyzer"><a href="#webpack-bundle-analyzer" class="headerlink" title="webpack-bundle-analyzer"></a>webpack-bundle-analyzer</h3><p>在打包后我们可能要对体积大的文件进行进一步优化，webpack 中有一个可视化的打包分析工具 webpack-bundle-analyzer。首先进行安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm add --save-dev webpack-bundle-analyzer</span><br></pre></td></tr></table></figure><p>并在 webpack.config.js 中进行配置：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title class_">BundleAnalyzerPlugin</span> = <span class="built_in">require</span>(<span class="string">&quot;webpack-bundle-analyzer&quot;</span>);</span><br><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">    <span class="attr">plugins</span>: [</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">BundleAnalyzerPlugin</span>.<span class="title class_">BundleAnalyzerPlugin</span>()</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在运行打包程序后，可在 <a href="http://127.0.0.1:8888/">http://127.0.0.1:8888/</a> 进行访问。</p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
